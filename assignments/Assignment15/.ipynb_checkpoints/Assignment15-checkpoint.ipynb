{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part of my codes are borrowed from past exam solution\n",
    "# haven't come up with better implementation yet\n",
    "from typing import Sequence, Tuple, Mapping, Dict, List\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from numpy.random import randint\n",
    "\n",
    "S = str\n",
    "DataType = Sequence[Sequence[Tuple[S, float]]]\n",
    "ProbFunc = Mapping[S, Mapping[S, float]]\n",
    "RewardFunc = Mapping[S, float]\n",
    "ValueFunc = Mapping[S, float]\n",
    "\n",
    "\n",
    "def get_state_return_samples(\n",
    "    data: DataType\n",
    ") -> Sequence[Tuple[S, float]]:\n",
    "    \"\"\"\n",
    "    prepare sequence of (state, return) pairs.\n",
    "    Note: (state, return) pairs is not same as (state, reward) pairs.\n",
    "    \"\"\"\n",
    "    return [(s, sum(r for (_, r) in l[i:]))\n",
    "            for l in data for i, (s, _) in enumerate(l)]\n",
    "\n",
    "\n",
    "def get_mc_value_function(\n",
    "    state_return_samples: Sequence[Tuple[S, float]]\n",
    ") -> ValueFunc:\n",
    "    \"\"\"\n",
    "    Implement tabular MC Value Function compatible with the interface defined above.\n",
    "    \"\"\"\n",
    "    sorted_samples = sorted(state_return_samples, key=itemgetter(0))\n",
    "    mc_value: Dict[S,float] ={}\n",
    "    for s, l in groupby(sorted_samples, itemgetter(0)):\n",
    "        r_list = []\n",
    "        for _, r in l:\n",
    "            r_list.append(r)\n",
    "        mc_value[s] = np.mean(r_list)\n",
    "    return mc_value\n",
    "\n",
    "\n",
    "def get_state_reward_next_state_samples(\n",
    "    data: DataType\n",
    ") -> Sequence[Tuple[S, float, S]]:\n",
    "    \"\"\"\n",
    "    prepare sequence of (state, reward, next_state) triples.\n",
    "    \"\"\"\n",
    "    samples: Sequence[Tuple[S, float, S]] = []\n",
    "    for d in data:\n",
    "        for i, (s, r) in enumerate(d):\n",
    "            if i == len(d) - 1:\n",
    "                next_s = 'T'\n",
    "            else:\n",
    "                next_s = d[i+1][0]\n",
    "            samples.append((s,r,next_s))\n",
    "    return samples\n",
    "\n",
    "\n",
    "def get_probability_and_reward_functions(\n",
    "    srs_samples: Sequence[Tuple[S, float, S]]\n",
    ") -> Tuple[ProbFunc, RewardFunc]:\n",
    "    \"\"\"\n",
    "    Implement code that produces the probability transitions and the\n",
    "    reward function compatible with the interface defined above.\n",
    "    \"\"\" \n",
    "    d:Dict[S, Squence(Tuple(float, S))] = {} #{s:(r,next_s)}\n",
    "    for s, l in groupby(sorted(srs_samples, key=itemgetter(0)),\n",
    "                        itemgetter(0)):\n",
    "        r_s_list = []\n",
    "        for _, r, next_s in l:\n",
    "            r_s_list.append((r,next_s))   \n",
    "        d[s] = r_s_list\n",
    "    prob_func = {s: {s1: len(list(l1)) / len(l) for s1, l1 in\n",
    "                     groupby(sorted(l, key=itemgetter(1)), itemgetter(1))\n",
    "                     if s1 != 'T'} for s, l in d.items()}\n",
    "                \n",
    "    reward_func: RewardFunc = {}\n",
    "    for s, l in d.items():\n",
    "        r_list =[]\n",
    "        for r, _ in l:\n",
    "            r_list.append(r)\n",
    "        reward_func[s]=np.mean(r_list)    \n",
    "    return prob_func, reward_func\n",
    "\n",
    "\n",
    "def get_mrp_value_function(\n",
    "    prob_func: ProbFunc,\n",
    "    reward_func: RewardFunc\n",
    ") -> ValueFunc:\n",
    "    \"\"\"\n",
    "    Implement code that calculates the MRP Value Function from the probability\n",
    "    transitions and reward function, compatible with the interface defined above.\n",
    "    Hint: Use the MRP Bellman Equation and simple linear algebra\n",
    "    \"\"\"\n",
    "    states_list = list(reward_func.keys())\n",
    "    reward_vec = np.array([reward_func[s] for s in states_list])\n",
    "    prob_matrix = np.array([[prob_func[s][s1] if s1 in prob_func[s] else 0.\n",
    "                            for s1 in states_list] for s in states_list])\n",
    "    vec = np.linalg.inv(np.eye(len(states_list)) - prob_matrix).dot(reward_vec)\n",
    "    return {states_list[i]: vec[i] for i in range(len(states_list))}\n",
    "\n",
    "def get_td_value_function(\n",
    "    srs_samples: Sequence[Tuple[S, float, S]],\n",
    "    num_updates: int = 300000,\n",
    "    learning_rate: float = 0.3,\n",
    "    learning_rate_decay: int = 30\n",
    ") -> ValueFunc:\n",
    "    \"\"\"\n",
    "    Implement tabular TD(0) (with experience replay) Value Function compatible\n",
    "    with the interface defined above. Let the step size (alpha) be:\n",
    "    learning_rate * (updates / learning_rate_decay + 1) ** -0.5\n",
    "    so that Robbins-Monro condition is satisfied for the sequence of step sizes.\n",
    "    \"\"\"\n",
    "    ret = {s: [0.] for s in set(x for x, _, _ in srs_samples)}\n",
    "    samples = len(srs_samples)\n",
    "    for updates in range(num_updates):\n",
    "        s, r, s1 = srs_samples[randint(samples, size=1)[0]]\n",
    "        ret[s].append(ret[s][-1] + learning_rate *\n",
    "                      (updates / learning_rate_decay + 1) ** -0.5\n",
    "                      * (r + (ret[s1][-1] if s1 != 'T' else 0.) - ret[s][-1]))\n",
    "    return {s: np.mean(v[-int(len(v) * 0.9):]) for s, v in ret.items()}\n",
    "\n",
    "\n",
    "def get_lstd_value_function(\n",
    "    srs_samples: Sequence[Tuple[S, float, S]]\n",
    ") -> ValueFunc:\n",
    "    \"\"\"\n",
    "    Implement LSTD Value Function compatible with the interface defined above.\n",
    "    Hint: Tabular is a special case of linear function approx where each feature\n",
    "    is an indicator variables for a corresponding state and each parameter is\n",
    "    the value function for the corresponding state.\n",
    "    \"\"\"\n",
    "    nt_states = list(set(x for x, _, _ in srs_samples))\n",
    "    num_nt_states = len(nt_states)\n",
    "    phi = np.eye(num_nt_states)\n",
    "    a_mat = np.zeros((num_nt_states, num_nt_states))\n",
    "    b_vec = np.zeros(num_nt_states)\n",
    "    for s, r, s1 in srs_samples:\n",
    "        p1 = phi[nt_states.index(s)]\n",
    "        p2 = phi[nt_states.index(s1)] if s1 != 'T' else np.zeros(num_nt_states)\n",
    "        a_mat += np.outer(p1, p1 - p2)\n",
    "        b_vec += p1 * r\n",
    "    return {nt_states[i]: v for i, v in\n",
    "            enumerate(np.linalg.inv(a_mat).dot(b_vec))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- MONTE CARLO VALUE FUNCTION --------------\n",
      "{'A': 9.571428571428571, 'B': 5.642857142857143}\n",
      "-------------- MRP VALUE FUNCTION ----------\n",
      "{'A': 12.93333333333333, 'B': 9.599999999999998}\n",
      "------------- TD VALUE FUNCTION --------------\n",
      "{'A': 12.913704303675987, 'B': 9.579351933872339}\n",
      "------------- LSTD VALUE FUNCTION --------------\n",
      "{'A': 12.933333333333334, 'B': 9.600000000000001}\n"
     ]
    }
   ],
   "source": [
    "given_data: DataType = [\n",
    "        [('A', 2.), ('A', 6.), ('B', 1.), ('B', 2.)],\n",
    "        [('A', 3.), ('B', 2.), ('A', 4.), ('B', 2.), ('B', 0.)],\n",
    "        [('B', 3.), ('B', 6.), ('A', 1.), ('B', 1.)],\n",
    "        [('A', 0.), ('B', 2.), ('A', 4.), ('B', 4.), ('B', 2.), ('B', 3.)],\n",
    "        [('B', 8.), ('B', 2.)]\n",
    "    ]\n",
    "\n",
    "sr_samps = get_state_return_samples(given_data)\n",
    "\n",
    "print(\"------------- MONTE CARLO VALUE FUNCTION --------------\")\n",
    "print(get_mc_value_function(sr_samps))\n",
    "\n",
    "srs_samps = get_state_reward_next_state_samples(given_data)\n",
    "\n",
    "pfunc, rfunc = get_probability_and_reward_functions(srs_samps)\n",
    "print(\"-------------- MRP VALUE FUNCTION ----------\")\n",
    "print(get_mrp_value_function(pfunc, rfunc))\n",
    "\n",
    "print(\"------------- TD VALUE FUNCTION --------------\")\n",
    "print(get_td_value_function(srs_samps))\n",
    "\n",
    "print(\"------------- LSTD VALUE FUNCTION --------------\")\n",
    "print(get_lstd_value_function(srs_samps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
